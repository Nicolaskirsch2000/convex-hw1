{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "70c01b9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cvxpy as cp\n",
    "from cvxpy.atoms.affine.wraps import psd_wrap\n",
    "from read_data import *\n",
    "from sklearn.model_selection import train_test_split\n",
    "#%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
    "#%%%%%%%%%%%%%%%%%%%%%%%%%       MGT - 418         %%%%%%%%%%%%%%%%%%%%%%%%%\n",
    "#%%%%%%%%%%%%%%      Convex Optimization - Project 2          %%%%%%%%%%%%%%\n",
    "#%%%%%%%%%%%%%%             2021-2022 Fall                    %%%%%%%%%%%%%%\n",
    "#%%%%%%%%%%%%%%      Learning the Kernel Function             %%%%%%%%%%%%%%\n",
    "#%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
    "#%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "23721993",
   "metadata": {},
   "outputs": [],
   "source": [
    "def kernel_learning(K1, K2, K3, y_tr, rho):\n",
    "    \"\"\"\n",
    "    Kernel learning for soft margin SVM. \n",
    "    Implementation of problem (5)\n",
    "    Use cvxpy.atoms.affine.psd_wrap for each G(\\hat K^l) matrix when it appear in the constraints and in the objective\n",
    "    \"\"\"\n",
    "    \n",
    "    #Y = np.outer(y_tr,y_tr.T)\n",
    "    \n",
    "    lambda_ = cp.Variable(len(y_tr))\n",
    "    z = cp.Variable(1)\n",
    "    \n",
    "    c = np.trace(K1+K2+K3)\n",
    "    \n",
    "    \n",
    "    obj = cp.Maximize((cp.norm(cp.vstack([lambda_]),\"nuc\") - c*z))\n",
    "    \n",
    "    cons = []\n",
    "    K = [K1,K2,K3]\n",
    "    #for k_i in K : \n",
    "        #cons.append(z * np.trace(k_i) >= 1/ (2 * rho) * cp.quad_form(lambda_, psd_wrap(np.diag(y_tr) @ k_i @ np.diag(y_tr))))\n",
    "    cons.append(lambda_<= 1)\n",
    "    cons.append(lambda_>=0)\n",
    "    cons.append(lambda_.T @ y_tr == 0)\n",
    "    \n",
    "    \n",
    "    prob = cp.Problem(obj, cons)\n",
    "    prob.solve(solver=cp.MOSEK, verbose = True)\n",
    "\n",
    "    \n",
    "    mu_opt1 = cons[0].dual_value\n",
    "    mu_opt2 = cons[1].dual_value\n",
    "    mu_opt3 = cons[2].dual_value\n",
    "\n",
    "    \n",
    "    b_opt = cons[3].dual_value\n",
    "    return mu_opt1, mu_opt2, mu_opt3, lambda_.value, b_opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "704fcbd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def svm_fit(kernel, y_tr, rho):\n",
    "    \"\"\"\n",
    "    Dual of soft-margin SVM problem (2)\n",
    "    Use cvxpy.atoms.affine.psd_wrap for each G(\\hat K^l) matrix when it appear in the constraints and in the objective\n",
    "    \"\"\"\n",
    "    n_tr = len(y_tr)\n",
    "    G =  ...\n",
    "    lambda_ = cp.Variable(n_tr)\n",
    "    dual_obj = cp.Maximize(... cp.quad_form(lambda_, psd_wrap(G)))\n",
    "    cons = []\n",
    "    ...\n",
    "    prob = cp.Problem(dual_obj, cons)\n",
    "    prob.solve(solver=cp.MOSEK)\n",
    "    lambda_opt = lambda_.value\n",
    "    b_opt =  ...\n",
    "    return lambda_opt, b_opt\n",
    "\n",
    "\n",
    "def svm_predict(kernel, y_tr, y_te, lambda_opt, b_opt, rho):\n",
    "    \"\"\"\n",
    "    Predict function for kernel SVM. \n",
    "    See lecture slide 183.\n",
    "    \"\"\"\n",
    "    n_te = len(y_te)\n",
    "    n_tr = len(y_tr)\n",
    "    ...\n",
    "    acc = ...\n",
    "    return acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7ad9d5f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = prepare_ionosphere_dataset()\n",
    "X_train, X_test, y_train, y_test = train_test_split(a[0],a[1],test_size = 0.2, random_state=0)\n",
    "\n",
    "def k_1(x,y, arg): \n",
    "    k_1 = (1.0 + np.dot(x.T,y))**int(arg)\n",
    "    return k_1\n",
    "\n",
    "def k_2(x,y,arg) : \n",
    "    k_2 = np.exp(-np.dot((x-y).T,(x-y))/2*0.5)\n",
    "    return k_2\n",
    "\n",
    "def k_3(x,y,arg): \n",
    "    k_3 = np.dot(x.T,y)\n",
    "    return k_3\n",
    "\n",
    "def K_creator(X_train, k_func,arg): \n",
    "    K = np.zeros((X_train.shape[0],X_train.shape[0]))\n",
    "    for i in range(X_train.shape[0]) : \n",
    "        for j in range(X_train.shape[0]): \n",
    "            K[i,j] = k_func(X_train[i,:],X_train[j,:],arg)\n",
    "    return K\n",
    "K_func = [k_1,k_2, k_3]\n",
    "args = [2.0,0.5,None]\n",
    "K = [None]*3\n",
    "for i in range(3):\n",
    "    K[i] = K_creator(X_train,K_func[i],args[i])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "96d3517a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============================================================================\n",
      "                                     CVXPY                                     \n",
      "                                    v1.1.15                                    \n",
      "===============================================================================\n",
      "(CVXPY) Nov 20 05:15:14 PM: Your problem has 281 variables, 3 constraints, and 0 parameters.\n",
      "(CVXPY) Nov 20 05:15:14 PM: It is compliant with the following grammars: \n",
      "(CVXPY) Nov 20 05:15:14 PM: (If you need to solve this problem multiple times, but with different data, consider using parameters.)\n",
      "(CVXPY) Nov 20 05:15:14 PM: CVXPY will first compile your problem; then, it will invoke a numerical solver to obtain a solution.\n"
     ]
    },
    {
     "ename": "DCPError",
     "evalue": "Problem does not follow DCP rules. Specifically:\nThe objective is not DCP, even though each sub-expression is.\nYou are trying to maximize a function that is convex.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mDCPError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_18516/2714949475.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkernel_learning\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mK\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mK\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mK\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_18516/3750410616.py\u001b[0m in \u001b[0;36mkernel_learning\u001b[1;34m(K1, K2, K3, y_tr, rho)\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m     \u001b[0mprob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mProblem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcons\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 28\u001b[1;33m     \u001b[0mprob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msolve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msolver\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mMOSEK\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     29\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\cvxpy\\problems\\problem.py\u001b[0m in \u001b[0;36msolve\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    460\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    461\u001b[0m             \u001b[0msolve_func\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mProblem\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_solve\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 462\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0msolve_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    463\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    464\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\cvxpy\\problems\\problem.py\u001b[0m in \u001b[0;36m_solve\u001b[1;34m(self, solver, warm_start, verbose, gp, qcp, requires_grad, enforce_dpp, **kwargs)\u001b[0m\n\u001b[0;32m    948\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    949\u001b[0m         data, solving_chain, inverse_data = self.get_problem_data(\n\u001b[1;32m--> 950\u001b[1;33m             solver, gp, enforce_dpp, verbose)\n\u001b[0m\u001b[0;32m    951\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    952\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\cvxpy\\problems\\problem.py\u001b[0m in \u001b[0;36mget_problem_data\u001b[1;34m(self, solver, gp, enforce_dpp, verbose)\u001b[0m\n\u001b[0;32m    569\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_cache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minvalidate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    570\u001b[0m             solving_chain = self._construct_chain(\n\u001b[1;32m--> 571\u001b[1;33m                 solver=solver, gp=gp, enforce_dpp=enforce_dpp)\n\u001b[0m\u001b[0;32m    572\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_cache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkey\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    573\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_cache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msolving_chain\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msolving_chain\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\cvxpy\\problems\\problem.py\u001b[0m in \u001b[0;36m_construct_chain\u001b[1;34m(self, solver, gp, enforce_dpp)\u001b[0m\n\u001b[0;32m    797\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sort_candidate_solvers\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcandidate_solvers\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    798\u001b[0m         return construct_solving_chain(self, candidate_solvers, gp=gp,\n\u001b[1;32m--> 799\u001b[1;33m                                        enforce_dpp=enforce_dpp)\n\u001b[0m\u001b[0;32m    800\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    801\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\cvxpy\\reductions\\solvers\\solving_chain.py\u001b[0m in \u001b[0;36mconstruct_solving_chain\u001b[1;34m(problem, candidates, gp, enforce_dpp)\u001b[0m\n\u001b[0;32m    153\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mproblem\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvariables\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    154\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mSolvingChain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreductions\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mConstantSolver\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 155\u001b[1;33m     \u001b[0mreductions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_reductions_for_problem_class\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mproblem\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcandidates\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    156\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    157\u001b[0m     \u001b[0mdpp_context\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'dcp'\u001b[0m \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mgp\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34m'dgp'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\cvxpy\\reductions\\solvers\\solving_chain.py\u001b[0m in \u001b[0;36m_reductions_for_problem_class\u001b[1;34m(problem, candidates, gp)\u001b[0m\n\u001b[0;32m     90\u001b[0m                        \"Consider calling solve() with `qcp=True`.\")\n\u001b[0;32m     91\u001b[0m         raise DCPError(\n\u001b[1;32m---> 92\u001b[1;33m             \"Problem does not follow DCP rules. Specifically:\\n\" + append)\n\u001b[0m\u001b[0;32m     93\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mgp\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mproblem\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_dgp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     94\u001b[0m         \u001b[0mappend\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbuild_non_disciplined_error_msg\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mproblem\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'DGP'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mDCPError\u001b[0m: Problem does not follow DCP rules. Specifically:\nThe objective is not DCP, even though each sub-expression is.\nYou are trying to maximize a function that is convex."
     ]
    }
   ],
   "source": [
    "result = kernel_learning(K[0],K[1],K[2],y_train,2)\n",
    "result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "0a4d8f73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.17634466e+02, 1.21774188e+02, 1.67254115e+02, ...,\n",
       "        1.48815380e+02, 2.77643224e+01, 9.75753779e-01],\n",
       "       [1.21774188e+02, 8.76571868e+01, 1.03023008e+02, ...,\n",
       "        8.93064708e+01, 6.76241268e+00, 2.86966455e-01],\n",
       "       [1.67254115e+02, 1.03023008e+02, 8.85992432e+02, ...,\n",
       "        1.72011488e+02, 2.41108988e+01, 6.89062500e+00],\n",
       "       ...,\n",
       "       [1.48815380e+02, 8.93064708e+01, 1.72011488e+02, ...,\n",
       "        1.22579283e+02, 1.73323764e+01, 9.13959900e-01],\n",
       "       [2.77643224e+01, 6.76241268e+00, 2.41108988e+01, ...,\n",
       "        1.73323764e+01, 1.64894332e+02, 1.44846845e+01],\n",
       "       [9.75753779e-01, 2.86966455e-01, 6.89062500e+00, ...,\n",
       "        9.13959900e-01, 1.44846845e+01, 1.57816406e+02]])"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "K[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "dfed2468",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_opt_kernel = []    \n",
    "acc_poly_kernel = []    \n",
    "acc_gauss_kernel = []    \n",
    "acc_linear_kernel = []    \n",
    "rho = 0.01\n",
    "data, labels = prepare_ionosphere_dataset()\n",
    "for iters in range(100): \n",
    "    ## Please do not change the random seed.\n",
    "    np.random.seed(iters)\n",
    "    ### Training-test split\n",
    "    msk = np.random.rand(data_normalized.shape[0]) <=...\n",
    "    x_tr = data[...]\n",
    "    x_te = data[...]\n",
    "    y_tr = labels[...]\n",
    "    y_te = labels[...]\n",
    " \n",
    "    n_tr = y_tr.shape[0]\n",
    "    n_te = y_te.shape[0]\n",
    "    n_tr = x_tr.shape[0]\n",
    "    n_te = x_te.shape[0]\n",
    "    \n",
    "    x_all = np.vstack([x_tr, x_te])\n",
    "    n_all = x_all.shape[0]\n",
    "\n",
    "    ## Prepare the initial choice of kernels \n",
    "    # It is recommended to prepare the kernels for all the training and the test data\n",
    "    # Then, the kernel size will be (n_tr + n_te)x(n_tr + n_te).\n",
    "    # Use only the training block (like K1[0:n_tr, 0:n_tr] ) to learn the classifier \n",
    "    # (for the functions svm_fit and kernel_learning).\n",
    "    # When predicting you may use the whole kernel as it is. \n",
    "    K1 = ...\n",
    "    K2 = ...\n",
    "    K3 = ...\n",
    "\n",
    "    mu_opt1, mu_opt2, mu_opt3, lambda_opt, b_opt = kernel_learning(...)\n",
    "    opt_kernel = ...\n",
    "    acc_opt_kernel.append(svm_predict(...))\n",
    "    \n",
    "    lambda_opt, b_opt = svm_fit(...)\n",
    "    acc_poly_kernel.append(svm_predict(...))\n",
    "    \n",
    "    lambda_opt, b_opt = svm_fit(...)\n",
    "    acc_gauss_kernel.append(svm_predict(...))\n",
    "    \n",
    "    lambda_opt, b_opt = svm_fit(...)\n",
    "    acc_linear_kernel.append(svm_predict(...)\n",
    "    print('Iteration-->' + str(iters))\n",
    "print('Average dual accuracy with optimal kernel is ' + str(np.mean(acc_opt_kernel)))\n",
    "print('Average dual accuracy with polynomial kernel is ' + str(np.mean(acc_poly_kernel)))\n",
    "print('Average dual accuracy with gaussian kernel is ' + str(np.mean(acc_gauss_kernel)))\n",
    "print('Average dual accuracy with linear kernel is ' + str(np.mean(acc_linear_kernel)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42e3f757",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
